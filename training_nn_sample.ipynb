{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor,Lambda\n",
    "from torch.optim import Adam, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    # encode the label into one-hot values (needed sometimes for calculating loss func)\n",
    "    # target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    # target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "train_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the data into dataloader type so that we can iterate through the datas and batches\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "938\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset)) # the number of data entries in the dataloader\n",
    "print(len(test_dataloader.dataset))\n",
    "# the number of batches, which equals to len(train_dataloader.dataset)/batch_size, \n",
    "# batch_size is initialized when initializing dataloader\n",
    "# ex) 10 = 60000/6000\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the shape of the first 2 batches of the training dataset/ test dataset\n",
    "# for X,y in train_dataloader:\n",
    "#     # print(X.shape)\n",
    "#     # print(y.shape)\n",
    "#     Xt,yt = next(iter(test_dataloader))\n",
    "#     # print(Xt[0])\n",
    "#     print(yt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model, only a MLP\n",
    "\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, img_shape, unit_dim=512):\n",
    "        super(MyNN,self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "        self.unit_dim = unit_dim\n",
    "    \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(), # 28x28 -> 784, can include flatten layer into the sequential layer\n",
    "            nn.Linear(img_shape[0]*img_shape[1],unit_dim), # 784 -> 512\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(stride=5,padding=3,kernel_size=2),\n",
    "            nn.Linear(unit_dim,unit_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(unit_dim,10), # 512 -> 10\n",
    "            # nn.Softmax(dim=1) # change this shape 10 from digit form to prob form (softmax)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        logist = self.linear(img) # can not output the result directly, loss_fn need to use its original shape to compute loss\n",
    "        return logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label = next(iter(train_dataloader))\n",
    "img_shape = sample_img.shape[2],sample_img.shape[3]\n",
    "model = MyNN(img_shape)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = Adam(model.parameters(),lr=lr)\n",
    "optimizer = SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, optimizer, loss_fn, model):\n",
    "    total_size = len(train_dataloader.dataset)\n",
    "    for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "        # get the current loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        # back prop & update weight matrices\n",
    "        # remember to clean up previous grad by zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch_idx % 5000 == 0: # for every 10 batch, we report once the result\n",
    "        # print(f\"Current loss: {loss:>7f}, Current progress: [{(batch_idx+1) * len(y):>5d}/{total_size:>5d}]\")\n",
    "\n",
    "def test_loop(test_dataloader, model):\n",
    "    correct = 0\n",
    "    size = len(test_dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for X,y in test_dataloader:\n",
    "            pred = model(X) # pred is in shape of batch_size x num_of_classes, y is in shape of batch_size x 1, need argmax\n",
    "\n",
    "            # pred.argmax(1) == y will return boolean values of each paring entry, .type will change false -> 0, true -> 1, and we sum them up\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    correct /= size\n",
    "    print(f\"Test acc: {correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.4206\n",
      "Test acc: 0.5804\n",
      "Test acc: 0.6133\n",
      "Test acc: 0.6346\n",
      "Test acc: 0.6457\n",
      "Test acc: 0.6521\n",
      "Test acc: 0.6662\n",
      "Test acc: 0.6769\n",
      "Test acc: 0.6942\n",
      "Test acc: 0.7112\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_epoch):\n",
    "    train_loop(train_dataloader,optimizer,loss_fn,model)\n",
    "    test_loop(test_dataloader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "torch.save(model.state_dict(),\"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.0587\n",
      "Test acc: 0.7112\n"
     ]
    }
   ],
   "source": [
    "# save it with weights\n",
    "model2 = MyNN((28,28))\n",
    "# before loading the weight from existing model\n",
    "test_loop(test_dataloader,model2)\n",
    "\n",
    "# after loading\n",
    "model2.load_state_dict(torch.load('model_weights.pth'))\n",
    "test_loop(test_dataloader,model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7112\n"
     ]
    }
   ],
   "source": [
    "# save it as a whole model shape\n",
    "torch.save(model,'model.pth')\n",
    "model3 = torch.load('model.pth')\n",
    "test_loop(test_dataloader,model3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
